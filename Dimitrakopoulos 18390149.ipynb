{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Βήμα 1: Εγκατάσταση απαραίτητων πακέτων**\n",
        "\n",
        "\n",
        "Εγκαθιστούμε τις απαραίτητες βιβλιοθήκες που θα χρησιμοποιήσουμε για την επεξεργασία κειμένου και την υλοποίηση της μηχανής αναζήτησης. Το nltk χρησιμοποιείται για την επεξεργασία φυσικής γλώσσας, ενώ pandas και json θα μας βοηθήσουν στη διαχείριση των δεδομένων."
      ],
      "metadata": {
        "id": "FHuH_mP_AUJu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYRUkxsZ9Cxg",
        "outputId": "520076dd-3f6a-4f19-c811-f837f6895f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk pandas scikit-learn rank-bm25 beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Βήμα 2: Συλλογή δεδομένων από τη Wikipedia\n",
        "\n",
        "\n",
        "Εδώ χρησιμοποιούμε έναν web scraper που εξάγει άρθρα από τη Wikipedia. Αντί να εισάγουμε δεδομένα χειροκίνητα, δημιουργούμε έναν αυτόματο μηχανισμό που συλλέγει και αποθηκεύει τα άρθρα σε αρχείο JSON."
      ],
      "metadata": {
        "id": "SbTSNoNzAgb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dimitrakopoulos Stylianos\n",
        "AM: 18390149\n",
        "Προγραμμα Σπουδων ΠΑΔΑ\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "def scrape_wikipedia_articles(url, num_articles=5):\n",
        "    base_url = \"https://en.wikipedia.org\"\n",
        "    articles = []\n",
        "    visited_urls = set()\n",
        "\n",
        "    def get_links(page_url):\n",
        "        \"\"\"Extract all Wikipedia article links from a given page.\"\"\"\n",
        "        response = requests.get(page_url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        links = []\n",
        "        for link in soup.find_all(\"a\", href=True):\n",
        "            href = link['href']\n",
        "            if href.startswith(\"/wiki/\") and \":\" not in href:  # Avoid non-article links\n",
        "                full_url = base_url + href\n",
        "                if full_url not in visited_urls:\n",
        "                    links.append(full_url)\n",
        "        return links\n",
        "\n",
        "    # Start with the main Wikipedia page\n",
        "    to_visit = [url]\n",
        "    while to_visit and len(articles) < num_articles:\n",
        "        current_url = to_visit.pop(0)\n",
        "        visited_urls.add(current_url)\n",
        "        try:\n",
        "            response = requests.get(current_url)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            title = soup.find(\"h1\").text.strip()\n",
        "            content = \"\\n\".join([p.text for p in soup.find_all(\"p\")])\n",
        "            if content:\n",
        "                articles.append({\"title\": title, \"url\": current_url, \"content\": content})\n",
        "                print(f\"Scraped: {title}\")\n",
        "            to_visit.extend(get_links(current_url))\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to scrape {current_url}: {e}\")\n",
        "\n",
        "    return articles\n",
        "\n",
        "# Scrape articles and save to JSON\n",
        "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
        "articles = scrape_wikipedia_articles(url, num_articles=5)\n",
        "\n",
        "# Save to JSON file\n",
        "with open(\"wikipedia_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(articles, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"Scraping complete. Data saved to wikipedia_articles.json.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ1udamw9kYD",
        "outputId": "5a5c3f0b-e809-4087-aee9-f26a9d1e0e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped: Main Page\n",
            "Scraped: Wikipedia\n",
            "Scraped: Free content\n",
            "Scraped: Encyclopedia\n",
            "Scraped: English language\n",
            "Scraping complete. Data saved to wikipedia_articles.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Βήμα 3: Προεπεξεργασία Κειμένου**\n",
        "\n",
        "\n",
        "Σε αυτό το στάδιο, επεξεργαζόμαστε τα δεδομένα με τεχνικές όπως tokenization, stemming, και stop-word removal. Αυτές οι διαδικασίες μας επιτρέπουν να μειώσουμε την πολυπλοκότητα του κειμένου και να βελτιώσουμε την ποιότητα των αποτελεσμάτων αναζήτησης."
      ],
      "metadata": {
        "id": "3JLGFMaJA-1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dimitrakopoulos Stylianos\n",
        "AM: 18390149\n",
        "Προγραμμα Σπουδων ΠΑΔΑ\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Φoρτωση των άρθρων από  JSON\n",
        "with open('wikipedia_articles.json', 'r', encoding='utf-8') as f:\n",
        "    articles_data = json.load(f)\n",
        "\n",
        "# Μετατροπή των δεδομένων σε DataFrame\n",
        "articles_df = pd.DataFrame(articles_data)\n",
        "\n",
        "# Συνάρτηση για την εξαγωγή λέξεων από το κείμενο\n",
        "def extract_tokens(text):\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    return words\n",
        "\n",
        "# tokenization\n",
        "articles_df['tokens'] = articles_df['content'].apply(extract_tokens)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Αφαίρεση stop words\n",
        "stop_words_set = set(stopwords.words('english'))\n",
        "articles_df['filtered_tokens'] = articles_df['tokens'].apply(\n",
        "    lambda words: [word for word in words if word not in stop_words_set]\n",
        ")\n",
        "\n",
        "# stemming\n",
        "stemmer = PorterStemmer()\n",
        "articles_df['stemmed_tokens'] = articles_df['filtered_tokens'].apply(\n",
        "    lambda words: [stemmer.stem(word) for word in words]\n",
        ")\n",
        "\n",
        "# Αποθήκευση του επεξεργασμένου συνόλου δεδομένων σε CSV\n",
        "articles_df[['title', 'stemmed_tokens']].to_csv('processed_articles.csv', index=False)\n",
        "print(\"Processing complete. Data saved to 'processed_articles.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVP9yUQw-SXz",
        "outputId": "121165ca-fef9-4679-a7bc-89e2bf7aa139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete. Data saved to 'processed_articles.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Βήμα 4: Δημιουργία Αντεστραμμένου Ευρετηρίου (Inverted Index)**\n",
        "\n",
        "\n",
        "Η δημιουργία του αντεστραμμένου ευρετηρίου μάς επιτρέπει να εντοπίζουμε γρήγορα τα άρθρα που περιέχουν συγκεκριμένους όρους. Η δομή αυτή χρησιμοποιείται σε πραγματικές μηχανές αναζήτησης για αποδοτική ανάκτηση εγγράφων."
      ],
      "metadata": {
        "id": "gYOl_BoGBHKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dimitrakopoulos Stylianos\n",
        "AM: 18390149\n",
        "Προγραμμα Σπουδων ΠΑΔΑ\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Eξαγωγη λέξεων από το κείμενο\n",
        "def process_text(text):\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    return words\n",
        "\n",
        "# Δημιουργία inverted index\n",
        "def generate_index(data):\n",
        "    index = defaultdict(set)\n",
        "\n",
        "    for _, row in data.iterrows():\n",
        "        doc_title = row['title']\n",
        "        words = process_text(row['content'])\n",
        "\n",
        "        for word in words:\n",
        "            index[word].add(doc_title)\n",
        "\n",
        "    return {term: list(docs) for term, docs in index.items()}\n",
        "\n",
        "# Φόρτωση του επεξεργασμένου αρχείου\n",
        "try:\n",
        "    articles_data = pd.read_csv(\"processed_articles.csv\")\n",
        "    articles_data['content'] = articles_data['stemmed_tokens'].apply(eval).apply(' '.join)\n",
        "    print(\"Processed data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'processed_articles.csv' not found.\")\n",
        "    exit()\n",
        "\n",
        "# Κατασκευή και αποθήκευση του inverted index\n",
        "print(\"Building the inverted index...\")\n",
        "inverted_index = generate_index(articles_data)\n",
        "print(\"Inverted index created.\")\n",
        "\n",
        "index_file = \"inverted_index.json\"\n",
        "with open(index_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(inverted_index, f, indent=4)\n",
        "\n",
        "print(f\"Inverted index saved to '{index_file}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkEir23x-iOb",
        "outputId": "d21a1650-4eb2-4543-9695-fce4e393e13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data loaded successfully.\n",
            "Building the inverted index...\n",
            "Inverted index created.\n",
            "Inverted index saved to 'inverted_index.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Βήμα 5: Ανάκτηση Πληροφορίας (Retrieval Models)**\n",
        "\n",
        "\n",
        "Σε αυτό το σημείο, εφαρμόζουμε τρεις διαφορετικές μεθόδους ανάκτησης πληροφορίας:\n",
        "\n",
        "\n",
        "*   Boolean Retrieval\n",
        "*   TF-IDF\n",
        "*   BM25"
      ],
      "metadata": {
        "id": "84zeP7oNBR50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dimitrakopoulos Stylianos\n",
        "AM: 18390149\n",
        "Προγραμμα Σπουδων ΠΑΔΑ\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "# Load εγγράφων από CSV\n",
        "def load_documents(file_path=\"processed_articles.csv\"):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df['stemmed_tokens'] = df['stemmed_tokens'].apply(eval)\n",
        "        titles = df['title'].tolist()\n",
        "        documents = df['stemmed_tokens'].apply(lambda tokens: ' '.join(tokens)).tolist()\n",
        "        return titles, documents\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading documents: {e}\")\n",
        "        exit()\n",
        "\n",
        "# Load inverted index\n",
        "def load_inverted_index(file_path=\"inverted_index.json\"):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: inverted_index.json not found.\")\n",
        "        exit()\n",
        "\n",
        "# Boolean Retrieval\n",
        "def boolean_search(query, inverted_index):\n",
        "    terms = query.split()\n",
        "    result_docs = set()\n",
        "\n",
        "    def get_docs(term):\n",
        "        return set(inverted_index.get(term, []))\n",
        "\n",
        "    current_docs = set()\n",
        "    operation = None\n",
        "\n",
        "    for term in terms:\n",
        "        if term.upper() in [\"AND\", \"OR\", \"NOT\"]:\n",
        "            operation = term.upper()\n",
        "        else:\n",
        "            docs = get_docs(term)\n",
        "            if operation == \"AND\":\n",
        "                current_docs &= docs\n",
        "            elif operation == \"OR\":\n",
        "                current_docs |= docs\n",
        "            elif operation == \"NOT\":\n",
        "                current_docs -= docs\n",
        "            else:\n",
        "                current_docs = docs\n",
        "\n",
        "    return current_docs\n",
        "\n",
        "# TF-IDF Retrieval\n",
        "def tfidf_retrieval(query, documents, inverted_index, titles):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    doc_vectors = vectorizer.fit_transform(documents)\n",
        "    query_vector = vectorizer.transform([query])\n",
        "\n",
        "    scores = (doc_vectors @ query_vector.T).toarray().flatten()\n",
        "    ranked_indices = np.argsort(scores)[::-1]\n",
        "\n",
        "    # Get Boolean filter\n",
        "    allowed_docs = boolean_search(query, inverted_index)\n",
        "\n",
        "    # Filter out disallowed documents\n",
        "    ranked_indices = [i for i in ranked_indices if titles[i] in allowed_docs]\n",
        "\n",
        "    return ranked_indices, scores[ranked_indices]\n",
        "\n",
        "# BM25 Retrieval\n",
        "def bm25_retrieval(query, documents, inverted_index, titles):\n",
        "    tokenized_docs = [doc.split() for doc in documents]\n",
        "    bm25 = BM25Okapi(tokenized_docs)\n",
        "    query_tokens = query.split()\n",
        "\n",
        "    scores = bm25.get_scores(query_tokens)\n",
        "    ranked_indices = np.argsort(scores)[::-1]\n",
        "\n",
        "    allowed_docs = boolean_search(query, inverted_index)\n",
        "\n",
        "\n",
        "    ranked_indices = [i for i in ranked_indices if titles[i] in allowed_docs]\n",
        "\n",
        "    return ranked_indices, scores[ranked_indices]\n"
      ],
      "metadata": {
        "id": "Q2WNE1pM-nhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Βήμα 6: Παραδείγματα Αναζητήσεων**\n",
        "\n",
        "\n",
        "Στο στάδιο αυτό, η μηχανή αναζήτησης παρέχει δύο επιλογές στον χρήστη:\n",
        "\n",
        "\n",
        "\n",
        "*   Εκτέλεση προκαθορισμένων δοκιμαστικών αναζητήσεων – Χρησιμοποιούνται προκαθορισμένα ερωτήματα ώστε να αξιολογηθεί η ακρίβεια και η αποτελεσματικότητα των τριών μοντέλων ανάκτησης πληροφορίας (Boolean Retrieval, TF-IDF, Okapi BM25).\n",
        "*   Εισαγωγή προσαρμοσμένης αναζήτησης – Ο χρήστης μπορεί να επιλέξει το μοντέλο ανάκτησης που επιθυμεί και να εισάγει δικό του ερώτημα για αναζήτηση στη συλλογή εγγράφων.\n",
        "\n"
      ],
      "metadata": {
        "id": "5QbRICx1Bk8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dimitrakopoulos Stylianos\n",
        "AM: 18390149\n",
        "Προγραμμα Σπουδων ΠΑΔΑ\n",
        "\"\"\"\n",
        "\n",
        "#from search_engine import load_documents, load_inverted_index, boolean_search, tfidf_retrieval, bm25_retrieval\n",
        "\n",
        "# Φόρτωση αρχειων\n",
        "titles, documents = load_documents(\"processed_articles.csv\")\n",
        "inverted_index = load_inverted_index(\"inverted_index.json\")\n",
        "\n",
        "# Test queries\n",
        "test_queries = [\n",
        "    {\"query\": \"maria\", \"expected\": {\"Main Page\"}},\n",
        "    {\"query\": \"maria AND trubnikova\", \"expected\": {\"Main Page\"}},\n",
        "    {\"query\": \"maria OR russian\", \"expected\": {\"Main Page\", \"Wikipedia\"}},\n",
        "    {\"query\": \"russian AND NOT maria\", \"expected\": {\"Wikipedia\"}},\n",
        "    {\"query\": \"NOT maria\", \"expected\": set()},  # Expect empty results\n",
        "    {\"query\": \"maria AND NOT russian\", \"expected\": set()},  # Expect empty if \"Main Page\" contains \"russian\"\n",
        "]\n",
        "\n",
        "# Function για test όλων των retrieval methods\n",
        "def run_tests(retrieval_function, method_name):\n",
        "    print(f\"\\n🔍 Testing {method_name} Retrieval...\")\n",
        "\n",
        "    for test in test_queries:\n",
        "        query = test[\"query\"]\n",
        "        expected = test[\"expected\"]\n",
        "\n",
        "        print(f\"\\n[DEBUG] Running {method_name} Search for query: {query}\")\n",
        "\n",
        "        if method_name == \"Boolean\":\n",
        "            result = retrieval_function(query, inverted_index)\n",
        "        else:\n",
        "            ranked_indices, scores = retrieval_function(query, documents, inverted_index, titles)\n",
        "            result = {titles[idx] for idx in ranked_indices} if ranked_indices else set()\n",
        "\n",
        "        print(f\"🔎 Expected: {expected}\")\n",
        "        print(f\"✅ {method_name} Search Result: {result}\")\n",
        "        print(f\"🟢 Pass: {result == expected}\\n\")\n",
        "\n",
        "# Function for custom user queries\n",
        "def run_custom_query():\n",
        "    print(\"\\nSelect a retrieval model:\")\n",
        "    print(\"1. Boolean Retrieval\")\n",
        "    print(\"2. TF-IDF Retrieval\")\n",
        "    print(\"3. Okapi BM25 Retrieval\")\n",
        "\n",
        "    choice = input(\"Enter your choice (1/2/3): \").strip()\n",
        "    model_mapping = {\"1\": (\"Boolean\", boolean_search), \"2\": (\"TF-IDF\", tfidf_retrieval), \"3\": (\"Okapi BM25\", bm25_retrieval)}\n",
        "\n",
        "    if choice not in model_mapping:\n",
        "        print(\"Invalid choice. Exiting...\")\n",
        "        return\n",
        "\n",
        "    model_name, model_function = model_mapping[choice]\n",
        "    query = input(\"\\nEnter your query: \").strip()\n",
        "\n",
        "    print(f\"\\n🔍 Running {model_name} Retrieval for query: {query}\")\n",
        "\n",
        "    if model_name == \"Boolean\":\n",
        "        result = model_function(query, inverted_index)\n",
        "    else:\n",
        "        ranked_indices, scores = model_function(query, documents, inverted_index, titles)\n",
        "        result = {titles[idx] for idx in ranked_indices} if ranked_indices else set()\n",
        "\n",
        "    print(f\"🔎 {model_name} Search Result: {result}\\n\")\n",
        "\n",
        "# Main execution flow\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Would you like to run the predefined test queries or enter a custom query?\")\n",
        "    print(\"1. Run predefined test queries\")\n",
        "    print(\"2. Enter custom query\")\n",
        "\n",
        "    user_choice = input(\"Enter your choice (1/2): \").strip()\n",
        "\n",
        "    if user_choice == \"1\":\n",
        "        run_tests(boolean_search, \"Boolean\")\n",
        "        run_tests(tfidf_retrieval, \"TF-IDF\")\n",
        "        run_tests(bm25_retrieval, \"Okapi BM25\")\n",
        "    elif user_choice == \"2\":\n",
        "        run_custom_query()\n",
        "    else:\n",
        "        print(\"Invalid choice. Exiting...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqg8OqD2-rVo",
        "outputId": "010d55de-119a-42da-df6d-73ab91a64ff1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Would you like to run the predefined test queries or enter a custom query?\n",
            "1. Run predefined test queries\n",
            "2. Enter custom query\n",
            "Enter your choice (1/2): 1\n",
            "\n",
            "🔍 Testing Boolean Retrieval...\n",
            "\n",
            "[DEBUG] Running Boolean Search for query: maria\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ Boolean Search Result: set()\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running Boolean Search for query: maria AND trubnikova\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ Boolean Search Result: set()\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running Boolean Search for query: maria OR russian\n",
            "🔎 Expected: {'Main Page', 'Wikipedia'}\n",
            "✅ Boolean Search Result: {'Wikipedia'}\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running Boolean Search for query: russian AND NOT maria\n",
            "🔎 Expected: {'Wikipedia'}\n",
            "✅ Boolean Search Result: {'Wikipedia'}\n",
            "🟢 Pass: True\n",
            "\n",
            "\n",
            "[DEBUG] Running Boolean Search for query: NOT maria\n",
            "🔎 Expected: set()\n",
            "✅ Boolean Search Result: set()\n",
            "🟢 Pass: True\n",
            "\n",
            "\n",
            "[DEBUG] Running Boolean Search for query: maria AND NOT russian\n",
            "🔎 Expected: set()\n",
            "✅ Boolean Search Result: set()\n",
            "🟢 Pass: True\n",
            "\n",
            "\n",
            "🔍 Testing TF-IDF Retrieval...\n",
            "\n",
            "[DEBUG] Running TF-IDF Search for query: maria\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ TF-IDF Search Result: set()\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running TF-IDF Search for query: maria AND trubnikova\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ TF-IDF Search Result: set()\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running TF-IDF Search for query: maria OR russian\n",
            "🔎 Expected: {'Main Page', 'Wikipedia'}\n",
            "✅ TF-IDF Search Result: {'Wikipedia'}\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running TF-IDF Search for query: russian AND NOT maria\n",
            "🔎 Expected: {'Wikipedia'}\n",
            "✅ TF-IDF Search Result: {'Wikipedia'}\n",
            "🟢 Pass: True\n",
            "\n",
            "\n",
            "[DEBUG] Running TF-IDF Search for query: NOT maria\n",
            "🔎 Expected: set()\n",
            "✅ TF-IDF Search Result: set()\n",
            "🟢 Pass: True\n",
            "\n",
            "\n",
            "[DEBUG] Running TF-IDF Search for query: maria AND NOT russian\n",
            "🔎 Expected: set()\n",
            "✅ TF-IDF Search Result: set()\n",
            "🟢 Pass: True\n",
            "\n",
            "\n",
            "🔍 Testing Okapi BM25 Retrieval...\n",
            "\n",
            "[DEBUG] Running Okapi BM25 Search for query: maria\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ Okapi BM25 Search Result: set()\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running Okapi BM25 Search for query: maria AND trubnikova\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ Okapi BM25 Search Result: set()\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running Okapi BM25 Search for query: maria OR russian\n",
            "🔎 Expected: {'Main Page', 'Wikipedia'}\n",
            "✅ Okapi BM25 Search Result: {'Wikipedia'}\n",
            "🟢 Pass: False\n",
            "\n",
            "\n",
            "[DEBUG] Running Okapi BM25 Search for query: russian AND NOT maria\n",
            "🔎 Expected: {'Wikipedia'}\n",
            "✅ Okapi BM25 Search Result: {'Wikipedia'}\n",
            "🟢 Pass: True\n",
            "\n",
            "\n",
            "[DEBUG] Running Okapi BM25 Search for query: NOT maria\n",
            "🔎 Expected: set()\n",
            "✅ Okapi BM25 Search Result: set()\n",
            "🟢 Pass: True\n",
            "\n",
            "\n",
            "[DEBUG] Running Okapi BM25 Search for query: maria AND NOT russian\n",
            "🔎 Expected: set()\n",
            "✅ Okapi BM25 Search Result: set()\n",
            "🟢 Pass: True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dimitrakopoulos Stylianos\n",
        "AM: 18390149\n",
        "Προγραμμα Σπουδων ΠΑΔΑ\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "#from search_engine import load_documents, load_inverted_index, boolean_search, tfidf_retrieval, bm25_retrieval\n",
        "\n",
        "# Load necessary data\n",
        "titles, documents = load_documents(\"processed_articles.csv\")\n",
        "inverted_index = load_inverted_index(\"inverted_index.json\")\n",
        "\n",
        "# Define ground truth for evaluation\n",
        "ground_truth = {\n",
        "    \"maria\": {\"Main Page\"},\n",
        "    \"maria AND trubnikova\": {\"Main Page\"},\n",
        "    \"maria OR russian\": {\"Main Page\", \"Wikipedia\"},\n",
        "    \"russian AND NOT maria\": {\"Wikipedia\"},\n",
        "    \"NOT maria\": set(),\n",
        "    \"maria AND NOT russian\": set()\n",
        "}\n",
        "\n",
        "# Function to compute evaluation metrics\n",
        "def evaluate_retrieval(retrieval_function, method_name, is_boolean=False):\n",
        "    print(f\"\\n🔍 Evaluating {method_name} Retrieval...\")\n",
        "\n",
        "    precision_scores, recall_scores, f1_scores = [], [], []\n",
        "\n",
        "    for query, expected in ground_truth.items():\n",
        "        print(f\"\\n[DEBUG] Running {method_name} for query: {query}\")\n",
        "\n",
        "        # Boolean retrieval returns a set, TF-IDF and BM25 return (ranked_indices, scores)\n",
        "        if is_boolean:\n",
        "            result = retrieval_function(query, inverted_index)\n",
        "        else:\n",
        "            ranked_indices, _ = retrieval_function(query, documents, inverted_index, titles)\n",
        "            result = {titles[idx] for idx in ranked_indices} if ranked_indices else set()\n",
        "\n",
        "        # Convert results and ground truth to binary format\n",
        "        all_documents = set(titles)\n",
        "        y_true = [1 if doc in expected else 0 for doc in all_documents]\n",
        "        y_pred = [1 if doc in result else 0 for doc in all_documents]\n",
        "\n",
        "        # Compute metrics\n",
        "        precision = precision_score(y_true, y_pred, zero_division=1)\n",
        "        recall = recall_score(y_true, y_pred, zero_division=1)\n",
        "        f1 = f1_score(y_true, y_pred, zero_division=1)\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        print(f\"🔎 Expected: {expected}\")\n",
        "        print(f\"✅ {method_name} Search Result: {result}\")\n",
        "        print(f\"🎯 Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "    # Compute average scores\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "    print(f\"\\n📊 {method_name} Evaluation Summary:\")\n",
        "    print(f\"⚡ Average Precision: {avg_precision:.4f}\")\n",
        "    print(f\"📈 Average Recall: {avg_recall:.4f}\")\n",
        "    print(f\"📊 Average F1-score: {avg_f1:.4f}\\n\")\n",
        "\n",
        "# Run evaluations\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate_retrieval(boolean_search, \"Boolean\", is_boolean=True)\n",
        "    evaluate_retrieval(tfidf_retrieval, \"TF-IDF\")\n",
        "    evaluate_retrieval(bm25_retrieval, \"Okapi BM25\")\n"
      ],
      "metadata": {
        "id": "xsD1VWyd_BW5",
        "outputId": "4cdb1c8f-1888-4744-e88f-6e51e31a528a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Evaluating Boolean Retrieval...\n",
            "\n",
            "[DEBUG] Running Boolean for query: maria\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ Boolean Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 0.0000, F1-score: 0.0000\n",
            "\n",
            "[DEBUG] Running Boolean for query: maria AND trubnikova\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ Boolean Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 0.0000, F1-score: 0.0000\n",
            "\n",
            "[DEBUG] Running Boolean for query: maria OR russian\n",
            "🔎 Expected: {'Main Page', 'Wikipedia'}\n",
            "✅ Boolean Search Result: {'Wikipedia'}\n",
            "🎯 Precision: 1.0000, Recall: 0.5000, F1-score: 0.6667\n",
            "\n",
            "[DEBUG] Running Boolean for query: russian AND NOT maria\n",
            "🔎 Expected: {'Wikipedia'}\n",
            "✅ Boolean Search Result: {'Wikipedia'}\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "[DEBUG] Running Boolean for query: NOT maria\n",
            "🔎 Expected: set()\n",
            "✅ Boolean Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "[DEBUG] Running Boolean for query: maria AND NOT russian\n",
            "🔎 Expected: set()\n",
            "✅ Boolean Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "📊 Boolean Evaluation Summary:\n",
            "⚡ Average Precision: 1.0000\n",
            "📈 Average Recall: 0.5833\n",
            "📊 Average F1-score: 0.6111\n",
            "\n",
            "\n",
            "🔍 Evaluating TF-IDF Retrieval...\n",
            "\n",
            "[DEBUG] Running TF-IDF for query: maria\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ TF-IDF Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 0.0000, F1-score: 0.0000\n",
            "\n",
            "[DEBUG] Running TF-IDF for query: maria AND trubnikova\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ TF-IDF Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 0.0000, F1-score: 0.0000\n",
            "\n",
            "[DEBUG] Running TF-IDF for query: maria OR russian\n",
            "🔎 Expected: {'Main Page', 'Wikipedia'}\n",
            "✅ TF-IDF Search Result: {'Wikipedia'}\n",
            "🎯 Precision: 1.0000, Recall: 0.5000, F1-score: 0.6667\n",
            "\n",
            "[DEBUG] Running TF-IDF for query: russian AND NOT maria\n",
            "🔎 Expected: {'Wikipedia'}\n",
            "✅ TF-IDF Search Result: {'Wikipedia'}\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "[DEBUG] Running TF-IDF for query: NOT maria\n",
            "🔎 Expected: set()\n",
            "✅ TF-IDF Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "[DEBUG] Running TF-IDF for query: maria AND NOT russian\n",
            "🔎 Expected: set()\n",
            "✅ TF-IDF Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "📊 TF-IDF Evaluation Summary:\n",
            "⚡ Average Precision: 1.0000\n",
            "📈 Average Recall: 0.5833\n",
            "📊 Average F1-score: 0.6111\n",
            "\n",
            "\n",
            "🔍 Evaluating Okapi BM25 Retrieval...\n",
            "\n",
            "[DEBUG] Running Okapi BM25 for query: maria\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ Okapi BM25 Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 0.0000, F1-score: 0.0000\n",
            "\n",
            "[DEBUG] Running Okapi BM25 for query: maria AND trubnikova\n",
            "🔎 Expected: {'Main Page'}\n",
            "✅ Okapi BM25 Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 0.0000, F1-score: 0.0000\n",
            "\n",
            "[DEBUG] Running Okapi BM25 for query: maria OR russian\n",
            "🔎 Expected: {'Main Page', 'Wikipedia'}\n",
            "✅ Okapi BM25 Search Result: {'Wikipedia'}\n",
            "🎯 Precision: 1.0000, Recall: 0.5000, F1-score: 0.6667\n",
            "\n",
            "[DEBUG] Running Okapi BM25 for query: russian AND NOT maria\n",
            "🔎 Expected: {'Wikipedia'}\n",
            "✅ Okapi BM25 Search Result: {'Wikipedia'}\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "[DEBUG] Running Okapi BM25 for query: NOT maria\n",
            "🔎 Expected: set()\n",
            "✅ Okapi BM25 Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "[DEBUG] Running Okapi BM25 for query: maria AND NOT russian\n",
            "🔎 Expected: set()\n",
            "✅ Okapi BM25 Search Result: set()\n",
            "🎯 Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
            "\n",
            "📊 Okapi BM25 Evaluation Summary:\n",
            "⚡ Average Precision: 1.0000\n",
            "📈 Average Recall: 0.5833\n",
            "📊 Average F1-score: 0.6111\n",
            "\n"
          ]
        }
      ]
    }
  ]
}